{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# WORKING GREAT NO ID GENERATION 02-18-2025\n",
    "\n",
    "import difflib\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.cluster import DBSCAN\n",
    "import unicodedata\n",
    "from unidecode import unidecode\n",
    "from ftfy import fix_text\n",
    "\n",
    "SUFFIXES = {\n",
    "    'MD', 'PhD', 'DDS', 'DVM', 'Esq', 'Jr', 'Sr', 'II', 'III', 'IV', 'V', 'VI',\n",
    "    'CPA', 'CFA', 'PE', 'MBE', 'OBE', 'CBE', 'KBE', 'DBE', 'RN', 'NP', 'RPh',\n",
    "    'Ret', 'Emeritus', 'USN', 'USA', 'USAF', 'MS', 'MA', 'MBA', 'JD', 'LLM',\n",
    "    'ThD', 'DMin', 'MTh', 'FAIA', 'FAAN', 'FACS', 'DPT', 'DC', 'DSc', 'MEng',\n",
    "    'MPH', 'MFA', 'MLIS', 'EdD', 'PsyD', 'DPhil', 'DPA', 'DNP', 'DO', 'DM',\n",
    "    'FRCS', 'FRCP', 'FRCOG', 'FRCPsych', 'FRSC', 'DCL', 'DLitt', 'DEng',\n",
    "    'FCA', 'FCMA', 'CGMA', 'CMgr', 'ChFC', 'CLU', 'CFP', 'AIA', 'FIA', 'ASA',\n",
    "    'ACAS', 'FCAS', 'FIA', 'MActSc', 'MSc', 'BSc', 'BA', 'BS', 'BEng', 'LLB'\n",
    "}\n",
    "\n",
    "PREFIXES = {\n",
    "    'Dr', 'Prof', 'Mr', 'Mrs', 'Ms', 'Miss', 'Mx', 'Master', 'Sir', 'Dame',\n",
    "    'Lady', 'Lord', 'Hon', 'Rev', 'Fr', 'Rabbi', 'Imam', 'Sheikh', 'Capt',\n",
    "    'Col', 'Maj', 'Lt', 'Cpl', 'Sgt', 'Gen', 'Adm', 'President', 'Senator',\n",
    "    'Governor', 'Ambassador', 'Judge', 'Justice', 'Attorney', 'Esq', 'Professor',\n",
    "    'The Honorable', 'Sr', 'Elder', 'Brother', 'Sister', 'Pastor', 'Bishop',\n",
    "    'Archbishop', 'Cardinal', 'Pope', 'Deacon', 'Venerable', 'Canon', 'Chaplain',\n",
    "    'Father', 'Mother', 'Abbess', 'Prior', 'Abbot', 'Metropolitan', 'Ayatollah',\n",
    "    'Mullah', 'Reverend Dr', 'Minister', 'Chancellor', 'Principal', 'Provost',\n",
    "    'Dean', 'Regent', 'Chairman', 'Chairwoman', 'Commander', 'Commodore',\n",
    "    'Brigadier', 'Marshal', 'Field Marshal', 'Rear Admiral', 'Vice Admiral',\n",
    "    'Air Chief Marshal', 'Air Marshal', 'Air Vice Marshal', 'General of the Army',\n",
    "    'Fleet Admiral', 'Supreme Commander', 'Grand Master', 'Warden', 'Sovereign'\n",
    "}\n",
    "\n",
    "def clean_name(name):\n",
    "    \"\"\"Robust cleaning with encoding repair and middle initial preservation\"\"\"\n",
    "    # Fix multi-layer encoding errors\n",
    "    name = fix_text(name, normalization='NFC')\n",
    "    \n",
    "    # Normalize Unicode and preserve middle initials\n",
    "    name = unicodedata.normalize('NFKD', name)\n",
    "    name = ''.join(c for c in name if not unicodedata.combining(c))\n",
    "    \n",
    "    # Transliterate special characters\n",
    "    name = unidecode(name)\n",
    "    \n",
    "    # Enhanced middle initial detection\n",
    "    name = re.sub(r'\\b([A-Z])[.]?\\s+', r'\\1. ', name)  # Standardize initials\n",
    "    \n",
    "    # Remove prefixes/suffixes\n",
    "    for prefix in sorted(PREFIXES, key=len, reverse=True):\n",
    "        name = re.sub(fr'(?i)^\\s*{re.escape(prefix)}\\b[.,]?\\s*', '', name)\n",
    "    \n",
    "    for suffix in sorted(SUFFIXES, key=len, reverse=True):\n",
    "        name = re.sub(fr'(?i)\\s*\\b{re.escape(suffix)}[.,]?\\s*$', '', name)\n",
    "    \n",
    "    # Final cleanup\n",
    "    name = re.sub(r'[^\\w\\s.]', ' ', name)  # Keep periods for initials\n",
    "    name = re.sub(r'[^\\w\\s.-]', ' ', name)  # Keep hyphens for compound names\n",
    "    name = re.sub(r'\\s+', ' ', name).strip().title()\n",
    "    \n",
    "    return name\n",
    "\n",
    "def group_names(names):\n",
    "    def parse_name(name):\n",
    "        cleaned = clean_name(name)\n",
    "        # Split names while preserving hyphenated components\n",
    "        parts = re.split(r'(?<!-)\\s+(?![a-z])', cleaned)  # Keep hyphenated names intact\n",
    "        return {\n",
    "            'original': name,\n",
    "            'first': parts[0] if parts else '',\n",
    "            'middles': parts[1:-1] if len(parts) > 2 else [],\n",
    "            'last': parts[-1] if parts else ''\n",
    "        }\n",
    "\n",
    "    def is_initial(part):\n",
    "        cleaned = part.replace('.', '').strip()\n",
    "        return len(cleaned) == 1 and cleaned.isalpha()\n",
    "\n",
    "    parsed = [parse_name(name) for name in names]\n",
    "    last_name_groups = {}\n",
    "    \n",
    "    for p in parsed:\n",
    "        last = p['last']\n",
    "        last_name_groups.setdefault(last, []).append(p)\n",
    "\n",
    "    grouped_results = {}\n",
    "\n",
    "    for last, group in last_name_groups.items():\n",
    "        # Process first names with hyphen handling\n",
    "        full_firsts = {}\n",
    "        initial_firsts = {}\n",
    "        for p in group:\n",
    "            first = p['first']\n",
    "            # Split hyphenated first names but keep original\n",
    "            base_first = re.split(r'-', first)[0].strip()\n",
    "            if is_initial(base_first):\n",
    "                initial = base_first.replace('.', '').upper()\n",
    "                initial_firsts.setdefault(initial, []).append(p)\n",
    "            else:\n",
    "                full_firsts[base_first] = first  # Store both base and full version\n",
    "\n",
    "        # Create first name mapping considering hyphens\n",
    "        first_initial_map = {}\n",
    "        for initial in initial_firsts:\n",
    "            candidates = [name for base, name in full_firsts.items() \n",
    "                        if base.upper().startswith(initial)]\n",
    "            if candidates:\n",
    "                # Select longest version (prefer hyphenated names)\n",
    "                first_initial_map[initial] = max(candidates, key=len)\n",
    "\n",
    "        # Process middle names with full name prioritization\n",
    "        middle_initial_map = {}\n",
    "        middle_full_map = {}\n",
    "        for p in group:\n",
    "            for middle in p['middles']:\n",
    "                if is_initial(middle):\n",
    "                    initial = middle.replace('.', '').upper()\n",
    "                    # Map initial to longest available full name\n",
    "                    if initial in middle_initial_map:\n",
    "                        current = middle_initial_map[initial]\n",
    "                        if len(current) == 1:  # Replace initial with full name\n",
    "                            middle_initial_map[initial] = middle_full_map.get(initial, current)\n",
    "                    else:\n",
    "                        middle_initial_map[initial] = middle_full_map.get(initial, middle)\n",
    "                else:\n",
    "                    initial = middle[0].upper()\n",
    "                    middle_full_map[initial] = middle\n",
    "                    # Update initial map if full name exists\n",
    "                    if initial in middle_initial_map:\n",
    "                        if len(middle) > len(middle_initial_map[initial]):\n",
    "                            middle_initial_map[initial] = middle\n",
    "\n",
    "        # Standardize names with enhanced mapping\n",
    "        for p in group:\n",
    "            # Handle hyphenated first names\n",
    "            base_first = re.split(r'-', p['first'])[0].strip()\n",
    "            if is_initial(base_first):\n",
    "                initial = base_first.replace('.', '').upper()\n",
    "                std_first = first_initial_map.get(initial, p['first'])\n",
    "            else:\n",
    "                std_first = full_firsts.get(base_first, p['first'])\n",
    "\n",
    "            # Standardize middle names\n",
    "            std_middles = []\n",
    "            for middle in p['middles']:\n",
    "                if is_initial(middle):\n",
    "                    initial = middle.replace('.', '').upper()\n",
    "                    std_middles.append(middle_initial_map.get(initial, middle))\n",
    "                else:\n",
    "                    std_middles.append(middle)\n",
    "\n",
    "            # Create standardized key with hyphen handling\n",
    "            std_key = (\n",
    "                std_first.strip().title(),\n",
    "                ' '.join(std_middles).strip(),\n",
    "                last.strip().title()\n",
    "            )\n",
    "            \n",
    "            if std_key not in grouped_results:\n",
    "                grouped_results[std_key] = []\n",
    "            grouped_results[std_key].append(p['original'])\n",
    "\n",
    "    # Enhanced merging logic for hyphenated and initial variations\n",
    "    merge_map = {}\n",
    "    for key in list(grouped_results.keys()):\n",
    "        first, middles, last = key\n",
    "        # Consider base first name (without hyphens)\n",
    "        base_first = re.split(r'-', first)[0].strip()\n",
    "        base_key = (base_first, last)\n",
    "        \n",
    "        current_middles = [m[0].upper() for m in middles.split() if m]\n",
    "\n",
    "        if base_key not in merge_map:\n",
    "            merge_map[base_key] = {\n",
    "                'main_key': key,\n",
    "                'variations': grouped_results[key],\n",
    "                'full_middles': middles.split(),\n",
    "                'middle_initials': current_middles\n",
    "            }\n",
    "        else:\n",
    "            existing = merge_map[base_key]\n",
    "            \n",
    "            # Check if middles are compatible through initials\n",
    "            existing_initials = existing['middle_initials']\n",
    "            if set(current_middles) == set(existing_initials):\n",
    "                existing['variations'].extend(grouped_results[key])\n",
    "                # Prefer longer middle name format\n",
    "                if len(middles.split()) > len(existing['full_middles']):\n",
    "                    existing['main_key'] = key\n",
    "                    existing['full_middles'] = middles.split()\n",
    "                del grouped_results[key]\n",
    "\n",
    "    # Update grouped_results with merged entries\n",
    "    for entry in merge_map.values():\n",
    "        if entry['main_key'] not in grouped_results:\n",
    "            grouped_results[entry['main_key']] = entry['variations']\n",
    "\n",
    "    # Final processing with cleaned canonical names\n",
    "    final_groups = []\n",
    "    for (first, middles, last), variations in grouped_results.items():\n",
    "        canonical_parts = [first]\n",
    "        if middles:\n",
    "            canonical_parts.extend(middles.split())\n",
    "        canonical_parts.append(last)\n",
    "        \n",
    "        cleaned_canonical = clean_name(' '.join(canonical_parts))\n",
    "        \n",
    "        final_groups.append({\n",
    "            'canonical_name': cleaned_canonical,\n",
    "            'variations': sorted(list(set(variations)))\n",
    "        })\n",
    "\n",
    "    final_groups.sort(key=lambda x: x['canonical_name'])\n",
    "    return final_groups\n",
    "\n",
    "def cluster_protected_names(names, eps=0.2):  # Reduced eps for tighter clusters\n",
    "    # Clean names and get rule groups\n",
    "    cleaned_names = [clean_name(n) for n in names]\n",
    "    rule_groups = group_names(names)\n",
    "    \n",
    "    # Create name to canonical mapping\n",
    "    name_to_canonical = {}\n",
    "    for group in rule_groups:\n",
    "        for variation in group['variations']:\n",
    "            name_to_canonical[variation] = group['canonical_name']\n",
    "    \n",
    "    # Build distance matrix using canonical names\n",
    "    n = len(names)\n",
    "    distance_matrix = np.ones((n, n))\n",
    "    \n",
    "    for i in range(n):\n",
    "        for j in range(n):\n",
    "            if name_to_canonical[names[i]] == name_to_canonical[names[j]]:\n",
    "                distance_matrix[i,j] = 0.0  # Force same cluster for same group\n",
    "            else:\n",
    "                # Compare cleaned canonical names\n",
    "                canon_i = clean_name(name_to_canonical.get(names[i], names[i]))\n",
    "                canon_j = clean_name(name_to_canonical.get(names[j], names[j]))\n",
    "                sim = difflib.SequenceMatcher(None, canon_i, canon_j).ratio()\n",
    "                distance_matrix[i,j] = 1 - sim\n",
    "            if i == j:\n",
    "                distance_matrix[i,j] = 0\n",
    "\n",
    "    # Cluster with DBSCAN\n",
    "    dbscan = DBSCAN(eps=eps, min_samples=1, metric='precomputed')\n",
    "    clusters = dbscan.fit_predict(distance_matrix)\n",
    "    \n",
    "    # Organize clusters\n",
    "    cluster_dict = {}\n",
    "    for idx, cluster_id in enumerate(clusters):\n",
    "        cluster_dict.setdefault(cluster_id, []).append(names[idx])\n",
    "    \n",
    "    return cluster_dict, rule_groups\n",
    "\n",
    "def create_attribution_df(rule_groups):\n",
    "    \"\"\"Create DataFrame with fully cleaned canonical names\"\"\"\n",
    "    attribution_map = []\n",
    "    \n",
    "    for group in rule_groups:\n",
    "        canonical = group['canonical_name']\n",
    "        for variation in group['variations']:\n",
    "            attribution_map.append({\n",
    "                'Original Name': variation,\n",
    "                'Attributed Name': canonical,\n",
    "                'Cleaned Name': clean_name(variation)  # For verification\n",
    "            })\n",
    "    \n",
    "    return pd.DataFrame(attribution_map)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    # Load names (make sure path is correct)\n",
    "    names = pd.read_excel(\"E:\\\\Students\\\\Ace\\\\NameMatcherClass\\\\trial_input_1.xlsx\")['name'].tolist()\n",
    "    \n",
    "    # Process names\n",
    "    clusters, rule_groups = cluster_protected_names(names, eps=0.2)\n",
    "    \n",
    "    # Create attribution DataFrame USING RULE GROUPS\n",
    "    result_df = create_attribution_df(rule_groups)  # <- Changed clusters to rule_groups\n",
    "    \n",
    "    # Print results\n",
    "    print(\"Name Attribution Results:\")\n",
    "    print(result_df.head())\n",
    "    \n",
    "    # Save to Excel\n",
    "    result_df.to_excel(\"E:\\\\Students\\\\Ace\\\\NameMatcherClass\\\\trial_output_0.2.xlsx\", index=False)\n",
    "    print(\"\\nSaved Output to Excel!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
